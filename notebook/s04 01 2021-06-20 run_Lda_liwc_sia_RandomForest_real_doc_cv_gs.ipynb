{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#packages\" data-toc-modified-id=\"packages-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>packages</a></span></li><li><span><a href=\"#get-clean-data\" data-toc-modified-id=\"get-clean-data-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>get clean data</a></span><ul class=\"toc-item\"><li><span><a href=\"#get-raw-data\" data-toc-modified-id=\"get-raw-data-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>get raw data</a></span></li><li><span><a href=\"#generate-df_liwc_sia\" data-toc-modified-id=\"generate-df_liwc_sia-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>generate df_liwc_sia</a></span></li><li><span><a href=\"#test\" data-toc-modified-id=\"test-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>test</a></span><ul class=\"toc-item\"><li><span><a href=\"#impact-of-stopword-removal\" data-toc-modified-id=\"impact-of-stopword-removal-2.3.1\"><span class=\"toc-item-num\">2.3.1&nbsp;&nbsp;</span>impact of stopword removal</a></span></li></ul></li><li><span><a href=\"#note\" data-toc-modified-id=\"note-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>note</a></span></li></ul></li><li><span><a href=\"#tokenize-text-data\" data-toc-modified-id=\"tokenize-text-data-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>tokenize text data</a></span><ul class=\"toc-item\"><li><span><a href=\"#prepare-data\" data-toc-modified-id=\"prepare-data-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>prepare data</a></span></li><li><span><a href=\"#tokenize-text-with-gensim\" data-toc-modified-id=\"tokenize-text-with-gensim-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>tokenize text with gensim</a></span></li></ul></li><li><span><a href=\"#get-bi_weapon_array\" data-toc-modified-id=\"get-bi_weapon_array-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>get <code>bi_weapon_array</code></a></span></li><li><span><a href=\"#cross-validation-&amp;-grid-search\" data-toc-modified-id=\"cross-validation-&amp;-grid-search-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>cross validation &amp; grid search</a></span><ul class=\"toc-item\"><li><span><a href=\"#grid-search\" data-toc-modified-id=\"grid-search-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>grid search</a></span></li><li><span><a href=\"#optimal-run\" data-toc-modified-id=\"optimal-run-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>optimal run</a></span></li></ul></li><li><span><a href=\"#test\" data-toc-modified-id=\"test-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>test</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pre-setting\n",
    "# automatically adjust the width of the notebook code cell\n",
    "# from IPython.core.display import display, HTML\n",
    "# display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "# if one module is changed, this line will automatically reload that module\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# display the figure in the notebook\n",
    "%matplotlib inline\n",
    "# To change the font size in acrobat\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['pdf.fonttype'] = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add path\n",
    "import os\n",
    "import sys\n",
    "src_dir = os.path.abspath(os.path.join(os.pardir, 'src'))\n",
    "if src_dir not in sys.path:\n",
    "    sys.path.insert(0, src_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import gensim as gs\n",
    "from collections import Counter\n",
    "import itertools\n",
    "\n",
    "# from sklearn.cross_validation import train_test_split # for old version sklearn <= 0.17.1\n",
    "from sklearn.model_selection import train_test_split, KFold # for old version sklearn\n",
    "\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "pd.options.display.max_columns = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.metrics import label_ranking_average_precision_score, label_ranking_loss\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation.evaluation import get_label_via_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation.evaluation import get_label_via_training, doc_class_evaluation_fscore, baseline_doc_class_evaluation_fscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from obtainLDA.obtainLDA import get_ptd_from_lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from obtainLDA.lda_liwc_sia_learn import run_lda_liwc_sia_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get clean data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_6p2_folder = os.path.abspath(os.path.join(os.pardir, 'data', 's2021_lumen_clean_data'))\n",
    "email_6p2_file = 's2021_06_20_01_lumen_clean_doc_sia_liwc_classify.csv'\n",
    "email_6p2_location = os.path.join(email_6p2_folder, email_6p2_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_6p2_df = pd.read_csv(email_6p2_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['raw_text_id', 'raw_text', 'text_type', 'nostop_stem_doc',\n",
       "       'nostop_stem_doc_len', 'clean_doc', 'clean_doc_len', 'pos_sia',\n",
       "       'compound_sia', 'neu_sia', 'neg_sia', 'posemo_liwc', 'negemo_liwc',\n",
       "       'anx_liwc', 'anger_liwc', 'sad_liwc', 'reward_liwc', 'risk_liwc',\n",
       "       'time_liwc', 'money_liwc', 'Authority or Expertise/Source Credibility',\n",
       "       'Blame/guilt', 'Commitment', 'Commitment- Call to Action',\n",
       "       'Commitment- Indignation', 'Emphasis', 'Gain framing', 'Liking',\n",
       "       'Loss framing', 'Objectivity', 'Reciprocation',\n",
       "       'Scarcity/Urgency/Opportunity', 'Social Proof',\n",
       "       'Social Proof- Admonition', 'Subjectivity'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "email_6p2_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate df_liwc_sia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['posemo_liwc',\n",
       " 'negemo_liwc',\n",
       " 'anx_liwc',\n",
       " 'anger_liwc',\n",
       " 'sad_liwc',\n",
       " 'reward_liwc',\n",
       " 'risk_liwc',\n",
       " 'time_liwc',\n",
       " 'money_liwc']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in email_6p2_df.columns if '_liwc' in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pos_sia', 'compound_sia', 'neu_sia', 'neg_sia']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in email_6p2_df.columns if '_sia' in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liwc_list = ['anx_liwc', 'anger_liwc', 'sad_liwc', 'reward_liwc', 'risk_liwc', 'time_liwc', 'money_liwc']\n",
    "len(liwc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sia_list = ['pos_sia', 'neg_sia']\n",
    "len(sia_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['anx_liwc',\n",
       "  'anger_liwc',\n",
       "  'sad_liwc',\n",
       "  'reward_liwc',\n",
       "  'risk_liwc',\n",
       "  'time_liwc',\n",
       "  'money_liwc',\n",
       "  'pos_sia',\n",
       "  'neg_sia'],\n",
       " 9)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liwc_sia_list = liwc_list + sia_list\n",
    "liwc_sia_list, len(liwc_sia_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tmp_liwc in liwc_list:\n",
    "    email_6p2_df[tmp_liwc] = email_6p2_df[tmp_liwc] / email_6p2_df.nostop_stem_doc_len * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_text_id</th>\n",
       "      <th>raw_text</th>\n",
       "      <th>text_type</th>\n",
       "      <th>nostop_stem_doc</th>\n",
       "      <th>nostop_stem_doc_len</th>\n",
       "      <th>clean_doc</th>\n",
       "      <th>clean_doc_len</th>\n",
       "      <th>pos_sia</th>\n",
       "      <th>compound_sia</th>\n",
       "      <th>neu_sia</th>\n",
       "      <th>neg_sia</th>\n",
       "      <th>posemo_liwc</th>\n",
       "      <th>negemo_liwc</th>\n",
       "      <th>anx_liwc</th>\n",
       "      <th>anger_liwc</th>\n",
       "      <th>sad_liwc</th>\n",
       "      <th>reward_liwc</th>\n",
       "      <th>risk_liwc</th>\n",
       "      <th>time_liwc</th>\n",
       "      <th>money_liwc</th>\n",
       "      <th>Authority or Expertise/Source Credibility</th>\n",
       "      <th>Blame/guilt</th>\n",
       "      <th>Commitment</th>\n",
       "      <th>Commitment- Call to Action</th>\n",
       "      <th>Commitment- Indignation</th>\n",
       "      <th>Emphasis</th>\n",
       "      <th>Gain framing</th>\n",
       "      <th>Liking</th>\n",
       "      <th>Loss framing</th>\n",
       "      <th>Objectivity</th>\n",
       "      <th>Reciprocation</th>\n",
       "      <th>Scarcity/Urgency/Opportunity</th>\n",
       "      <th>Social Proof</th>\n",
       "      <th>Social Proof- Admonition</th>\n",
       "      <th>Subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>\"A Baker Swept By,\" by Edward Hirsch Audio: Re...</td>\n",
       "      <td>news left</td>\n",
       "      <td>baker swept edward hirsch audio read author al...</td>\n",
       "      <td>69</td>\n",
       "      <td>a baker swept by by edward hirsch audio read b...</td>\n",
       "      <td>137</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.7506</td>\n",
       "      <td>0.905</td>\n",
       "      <td>0.020</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.449275</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.449275</td>\n",
       "      <td>20.289855</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>\"Get Out\" Won’t Have A 100% Rating On Rotten T...</td>\n",
       "      <td>news left</td>\n",
       "      <td>get rate rotten tomato ever fact jordan peel g...</td>\n",
       "      <td>99</td>\n",
       "      <td>get out won t have a rating on rotten tomatoes...</td>\n",
       "      <td>194</td>\n",
       "      <td>0.115</td>\n",
       "      <td>-0.5607</td>\n",
       "      <td>0.772</td>\n",
       "      <td>0.113</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.070707</td>\n",
       "      <td>1.010101</td>\n",
       "      <td>10.101010</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>\"Know Your Rights or Your Safety Is At Risk In...</td>\n",
       "      <td>russian ad</td>\n",
       "      <td>know right safeti risk interact polic shock vi...</td>\n",
       "      <td>76</td>\n",
       "      <td>know your rights or your safety is at risk in ...</td>\n",
       "      <td>146</td>\n",
       "      <td>0.068</td>\n",
       "      <td>-0.8751</td>\n",
       "      <td>0.790</td>\n",
       "      <td>0.142</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1.315789</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.631579</td>\n",
       "      <td>5.263158</td>\n",
       "      <td>3.947368</td>\n",
       "      <td>1.315789</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>\"Nancy Pelosi was drunk again today,\" begins a...</td>\n",
       "      <td>fake news</td>\n",
       "      <td>nanci pelosi drunk today begin post recent sha...</td>\n",
       "      <td>90</td>\n",
       "      <td>nancy pelosi was drunk again today begins a po...</td>\n",
       "      <td>172</td>\n",
       "      <td>0.078</td>\n",
       "      <td>-0.1027</td>\n",
       "      <td>0.831</td>\n",
       "      <td>0.092</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.555556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.222222</td>\n",
       "      <td>1.111111</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>\"Obama out\": POTUS ends speech with viral mic ...</td>\n",
       "      <td>news left</td>\n",
       "      <td>obama potu end speech viral mic drop presid ba...</td>\n",
       "      <td>58</td>\n",
       "      <td>obama out potus ends speech with viral mic dro...</td>\n",
       "      <td>105</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.1779</td>\n",
       "      <td>0.913</td>\n",
       "      <td>0.040</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.724138</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.344828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   raw_text_id                                           raw_text   text_type  \\\n",
       "0            0  \"A Baker Swept By,\" by Edward Hirsch Audio: Re...   news left   \n",
       "1            1  \"Get Out\" Won’t Have A 100% Rating On Rotten T...   news left   \n",
       "2            3  \"Know Your Rights or Your Safety Is At Risk In...  russian ad   \n",
       "3            4  \"Nancy Pelosi was drunk again today,\" begins a...   fake news   \n",
       "4            5  \"Obama out\": POTUS ends speech with viral mic ...   news left   \n",
       "\n",
       "                                     nostop_stem_doc  nostop_stem_doc_len  \\\n",
       "0  baker swept edward hirsch audio read author al...                   69   \n",
       "1  get rate rotten tomato ever fact jordan peel g...                   99   \n",
       "2  know right safeti risk interact polic shock vi...                   76   \n",
       "3  nanci pelosi drunk today begin post recent sha...                   90   \n",
       "4  obama potu end speech viral mic drop presid ba...                   58   \n",
       "\n",
       "                                           clean_doc  clean_doc_len  pos_sia  \\\n",
       "0  a baker swept by by edward hirsch audio read b...            137    0.075   \n",
       "1  get out won t have a rating on rotten tomatoes...            194    0.115   \n",
       "2  know your rights or your safety is at risk in ...            146    0.068   \n",
       "3  nancy pelosi was drunk again today begins a po...            172    0.078   \n",
       "4  obama out potus ends speech with viral mic dro...            105    0.047   \n",
       "\n",
       "   compound_sia  neu_sia  neg_sia  posemo_liwc  negemo_liwc  anx_liwc  \\\n",
       "0        0.7506    0.905    0.020            4            1  0.000000   \n",
       "1       -0.5607    0.772    0.113            6            6  0.000000   \n",
       "2       -0.8751    0.790    0.142            4            2  1.315789   \n",
       "3       -0.1027    0.831    0.092            6            1  0.000000   \n",
       "4        0.1779    0.913    0.040            2            1  0.000000   \n",
       "\n",
       "   anger_liwc  sad_liwc  reward_liwc  risk_liwc  time_liwc  money_liwc  \\\n",
       "0         0.0  1.449275     0.000000   1.449275  20.289855    0.000000   \n",
       "1         0.0  0.000000     7.070707   1.010101  10.101010    0.000000   \n",
       "2         0.0  0.000000     2.631579   5.263158   3.947368    1.315789   \n",
       "3         0.0  0.000000     5.555556   0.000000  12.222222    1.111111   \n",
       "4         0.0  0.000000     1.724138   0.000000  10.344828    0.000000   \n",
       "\n",
       "   Authority or Expertise/Source Credibility  Blame/guilt  Commitment  \\\n",
       "0                                          0            0           0   \n",
       "1                                          1            1           1   \n",
       "2                                          0            1           1   \n",
       "3                                          1            0           0   \n",
       "4                                          1            0           1   \n",
       "\n",
       "   Commitment- Call to Action  Commitment- Indignation  Emphasis  \\\n",
       "0                           0                        0         0   \n",
       "1                           0                        0         0   \n",
       "2                           1                        1         1   \n",
       "3                           0                        0         0   \n",
       "4                           0                        0         0   \n",
       "\n",
       "   Gain framing  Liking  Loss framing  Objectivity  Reciprocation  \\\n",
       "0             0       0             0            0              0   \n",
       "1             0       1             0            1              0   \n",
       "2             0       0             0            1              0   \n",
       "3             0       0             0            1              0   \n",
       "4             0       1             0            1              0   \n",
       "\n",
       "   Scarcity/Urgency/Opportunity  Social Proof  Social Proof- Admonition  \\\n",
       "0                             1             0                         0   \n",
       "1                             0             0                         0   \n",
       "2                             0             1                         1   \n",
       "3                             0             1                         0   \n",
       "4                             0             1                         0   \n",
       "\n",
       "   Subjectivity  \n",
       "0             1  \n",
       "1             1  \n",
       "2             1  \n",
       "3             1  \n",
       "4             1  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "email_6p2_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_liwc_sia = email_6p2_df[liwc_sia_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2771, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anx_liwc</th>\n",
       "      <th>anger_liwc</th>\n",
       "      <th>sad_liwc</th>\n",
       "      <th>reward_liwc</th>\n",
       "      <th>risk_liwc</th>\n",
       "      <th>time_liwc</th>\n",
       "      <th>money_liwc</th>\n",
       "      <th>pos_sia</th>\n",
       "      <th>neg_sia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.449275</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.449275</td>\n",
       "      <td>20.289855</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.070707</td>\n",
       "      <td>1.010101</td>\n",
       "      <td>10.101010</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.315789</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.631579</td>\n",
       "      <td>5.263158</td>\n",
       "      <td>3.947368</td>\n",
       "      <td>1.315789</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.555556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.222222</td>\n",
       "      <td>1.111111</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.724138</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.344828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.040</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   anx_liwc  anger_liwc  sad_liwc  reward_liwc  risk_liwc  time_liwc  \\\n",
       "0  0.000000         0.0  1.449275     0.000000   1.449275  20.289855   \n",
       "1  0.000000         0.0  0.000000     7.070707   1.010101  10.101010   \n",
       "2  1.315789         0.0  0.000000     2.631579   5.263158   3.947368   \n",
       "3  0.000000         0.0  0.000000     5.555556   0.000000  12.222222   \n",
       "4  0.000000         0.0  0.000000     1.724138   0.000000  10.344828   \n",
       "\n",
       "   money_liwc  pos_sia  neg_sia  \n",
       "0    0.000000    0.075    0.020  \n",
       "1    0.000000    0.115    0.113  \n",
       "2    1.315789    0.068    0.142  \n",
       "3    1.111111    0.078    0.092  \n",
       "4    0.000000    0.047    0.040  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_liwc_sia.shape)\n",
    "df_liwc_sia.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "liwc_sia_array = df_liwc_sia.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2771, 9)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liwc_sia_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2771, 35)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_text_id</th>\n",
       "      <th>raw_text</th>\n",
       "      <th>text_type</th>\n",
       "      <th>nostop_stem_doc</th>\n",
       "      <th>nostop_stem_doc_len</th>\n",
       "      <th>clean_doc</th>\n",
       "      <th>clean_doc_len</th>\n",
       "      <th>pos_sia</th>\n",
       "      <th>compound_sia</th>\n",
       "      <th>neu_sia</th>\n",
       "      <th>neg_sia</th>\n",
       "      <th>posemo_liwc</th>\n",
       "      <th>negemo_liwc</th>\n",
       "      <th>anx_liwc</th>\n",
       "      <th>anger_liwc</th>\n",
       "      <th>sad_liwc</th>\n",
       "      <th>reward_liwc</th>\n",
       "      <th>risk_liwc</th>\n",
       "      <th>time_liwc</th>\n",
       "      <th>money_liwc</th>\n",
       "      <th>Authority or Expertise/Source Credibility</th>\n",
       "      <th>Blame/guilt</th>\n",
       "      <th>Commitment</th>\n",
       "      <th>Commitment- Call to Action</th>\n",
       "      <th>Commitment- Indignation</th>\n",
       "      <th>Emphasis</th>\n",
       "      <th>Gain framing</th>\n",
       "      <th>Liking</th>\n",
       "      <th>Loss framing</th>\n",
       "      <th>Objectivity</th>\n",
       "      <th>Reciprocation</th>\n",
       "      <th>Scarcity/Urgency/Opportunity</th>\n",
       "      <th>Social Proof</th>\n",
       "      <th>Social Proof- Admonition</th>\n",
       "      <th>Subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>\"A Baker Swept By,\" by Edward Hirsch Audio: Re...</td>\n",
       "      <td>news left</td>\n",
       "      <td>baker swept edward hirsch audio read author al...</td>\n",
       "      <td>69</td>\n",
       "      <td>a baker swept by by edward hirsch audio read b...</td>\n",
       "      <td>137</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.7506</td>\n",
       "      <td>0.905</td>\n",
       "      <td>0.020</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.449275</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.449275</td>\n",
       "      <td>20.289855</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>\"Get Out\" Won’t Have A 100% Rating On Rotten T...</td>\n",
       "      <td>news left</td>\n",
       "      <td>get rate rotten tomato ever fact jordan peel g...</td>\n",
       "      <td>99</td>\n",
       "      <td>get out won t have a rating on rotten tomatoes...</td>\n",
       "      <td>194</td>\n",
       "      <td>0.115</td>\n",
       "      <td>-0.5607</td>\n",
       "      <td>0.772</td>\n",
       "      <td>0.113</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.070707</td>\n",
       "      <td>1.010101</td>\n",
       "      <td>10.101010</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>\"Know Your Rights or Your Safety Is At Risk In...</td>\n",
       "      <td>russian ad</td>\n",
       "      <td>know right safeti risk interact polic shock vi...</td>\n",
       "      <td>76</td>\n",
       "      <td>know your rights or your safety is at risk in ...</td>\n",
       "      <td>146</td>\n",
       "      <td>0.068</td>\n",
       "      <td>-0.8751</td>\n",
       "      <td>0.790</td>\n",
       "      <td>0.142</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1.315789</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.631579</td>\n",
       "      <td>5.263158</td>\n",
       "      <td>3.947368</td>\n",
       "      <td>1.315789</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>\"Nancy Pelosi was drunk again today,\" begins a...</td>\n",
       "      <td>fake news</td>\n",
       "      <td>nanci pelosi drunk today begin post recent sha...</td>\n",
       "      <td>90</td>\n",
       "      <td>nancy pelosi was drunk again today begins a po...</td>\n",
       "      <td>172</td>\n",
       "      <td>0.078</td>\n",
       "      <td>-0.1027</td>\n",
       "      <td>0.831</td>\n",
       "      <td>0.092</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.555556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.222222</td>\n",
       "      <td>1.111111</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>\"Obama out\": POTUS ends speech with viral mic ...</td>\n",
       "      <td>news left</td>\n",
       "      <td>obama potu end speech viral mic drop presid ba...</td>\n",
       "      <td>58</td>\n",
       "      <td>obama out potus ends speech with viral mic dro...</td>\n",
       "      <td>105</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.1779</td>\n",
       "      <td>0.913</td>\n",
       "      <td>0.040</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.724138</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.344828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   raw_text_id                                           raw_text   text_type  \\\n",
       "0            0  \"A Baker Swept By,\" by Edward Hirsch Audio: Re...   news left   \n",
       "1            1  \"Get Out\" Won’t Have A 100% Rating On Rotten T...   news left   \n",
       "2            3  \"Know Your Rights or Your Safety Is At Risk In...  russian ad   \n",
       "3            4  \"Nancy Pelosi was drunk again today,\" begins a...   fake news   \n",
       "4            5  \"Obama out\": POTUS ends speech with viral mic ...   news left   \n",
       "\n",
       "                                     nostop_stem_doc  nostop_stem_doc_len  \\\n",
       "0  baker swept edward hirsch audio read author al...                   69   \n",
       "1  get rate rotten tomato ever fact jordan peel g...                   99   \n",
       "2  know right safeti risk interact polic shock vi...                   76   \n",
       "3  nanci pelosi drunk today begin post recent sha...                   90   \n",
       "4  obama potu end speech viral mic drop presid ba...                   58   \n",
       "\n",
       "                                           clean_doc  clean_doc_len  pos_sia  \\\n",
       "0  a baker swept by by edward hirsch audio read b...            137    0.075   \n",
       "1  get out won t have a rating on rotten tomatoes...            194    0.115   \n",
       "2  know your rights or your safety is at risk in ...            146    0.068   \n",
       "3  nancy pelosi was drunk again today begins a po...            172    0.078   \n",
       "4  obama out potus ends speech with viral mic dro...            105    0.047   \n",
       "\n",
       "   compound_sia  neu_sia  neg_sia  posemo_liwc  negemo_liwc  anx_liwc  \\\n",
       "0        0.7506    0.905    0.020            4            1  0.000000   \n",
       "1       -0.5607    0.772    0.113            6            6  0.000000   \n",
       "2       -0.8751    0.790    0.142            4            2  1.315789   \n",
       "3       -0.1027    0.831    0.092            6            1  0.000000   \n",
       "4        0.1779    0.913    0.040            2            1  0.000000   \n",
       "\n",
       "   anger_liwc  sad_liwc  reward_liwc  risk_liwc  time_liwc  money_liwc  \\\n",
       "0         0.0  1.449275     0.000000   1.449275  20.289855    0.000000   \n",
       "1         0.0  0.000000     7.070707   1.010101  10.101010    0.000000   \n",
       "2         0.0  0.000000     2.631579   5.263158   3.947368    1.315789   \n",
       "3         0.0  0.000000     5.555556   0.000000  12.222222    1.111111   \n",
       "4         0.0  0.000000     1.724138   0.000000  10.344828    0.000000   \n",
       "\n",
       "   Authority or Expertise/Source Credibility  Blame/guilt  Commitment  \\\n",
       "0                                          0            0           0   \n",
       "1                                          1            1           1   \n",
       "2                                          0            1           1   \n",
       "3                                          1            0           0   \n",
       "4                                          1            0           1   \n",
       "\n",
       "   Commitment- Call to Action  Commitment- Indignation  Emphasis  \\\n",
       "0                           0                        0         0   \n",
       "1                           0                        0         0   \n",
       "2                           1                        1         1   \n",
       "3                           0                        0         0   \n",
       "4                           0                        0         0   \n",
       "\n",
       "   Gain framing  Liking  Loss framing  Objectivity  Reciprocation  \\\n",
       "0             0       0             0            0              0   \n",
       "1             0       1             0            1              0   \n",
       "2             0       0             0            1              0   \n",
       "3             0       0             0            1              0   \n",
       "4             0       1             0            1              0   \n",
       "\n",
       "   Scarcity/Urgency/Opportunity  Social Proof  Social Proof- Admonition  \\\n",
       "0                             1             0                         0   \n",
       "1                             0             0                         0   \n",
       "2                             0             1                         1   \n",
       "3                             0             1                         0   \n",
       "4                             0             1                         0   \n",
       "\n",
       "   Subjectivity  \n",
       "0             1  \n",
       "1             1  \n",
       "2             1  \n",
       "3             1  \n",
       "4             1  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(email_6p2_df.shape)\n",
    "email_6p2_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['raw_text_id', 'raw_text', 'text_type', 'nostop_stem_doc',\n",
       "       'nostop_stem_doc_len', 'clean_doc', 'clean_doc_len', 'pos_sia',\n",
       "       'compound_sia', 'neu_sia', 'neg_sia', 'posemo_liwc', 'negemo_liwc',\n",
       "       'anx_liwc', 'anger_liwc', 'sad_liwc', 'reward_liwc', 'risk_liwc',\n",
       "       'time_liwc', 'money_liwc', 'Authority or Expertise/Source Credibility',\n",
       "       'Blame/guilt', 'Commitment', 'Commitment- Call to Action',\n",
       "       'Commitment- Indignation', 'Emphasis', 'Gain framing', 'Liking',\n",
       "       'Loss framing', 'Objectivity', 'Reciprocation',\n",
       "       'Scarcity/Urgency/Opportunity', 'Social Proof',\n",
       "       'Social Proof- Admonition', 'Subjectivity'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "email_6p2_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['posemo_liwc',\n",
       " 'negemo_liwc',\n",
       " 'anx_liwc',\n",
       " 'anger_liwc',\n",
       " 'sad_liwc',\n",
       " 'reward_liwc',\n",
       " 'risk_liwc',\n",
       " 'time_liwc',\n",
       " 'money_liwc']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in email_6p2_df.columns if '_liwc' in i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### impact of stopword removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_list_nostop_stem = [i.split() for i in email_6p2_df.nostop_stem_doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_word_list_nostop_stem = [j for i in doc_list_nostop_stem for j in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(183442, 14938)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_word_list_nostop_stem), len(set(all_word_list_nostop_stem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_list_stop_nostem = [i.split() for i in email_6p2_df.clean_doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_word_list_stop_nostem = [j for i in doc_list_stop_nostem for j in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(316088, 21328)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_word_list_stop_nostem), len(set(all_word_list_stop_nostem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7230950382137133, 0.4277681081804794)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_word_list_stop_nostem) / len(all_word_list_nostop_stem) - 1, len(set(all_word_list_stop_nostem)) / len(set(all_word_list_nostop_stem)) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_len_list_nostop_stem = [len(i) for i in doc_list_nostop_stem]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_len_list_stop_nostem = [len(i) for i in doc_list_stop_nostem]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_len_nostop_stem_array = np.array(doc_len_list_nostop_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "183442"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_len_nostop_stem_array.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66.20064958498737, 66.0)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_len_nostop_stem_array.mean(), np.median(doc_len_nostop_stem_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_len_stop_nostem_array = np.array(doc_len_list_stop_nostem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114.07001082641645, 113.0)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_len_stop_nostem_array.mean(), np.median(doc_len_stop_nostem_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### note"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- there is no short pre-processed doc\n",
    "- there is 1,763 emails in total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tokenize text data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_list = [i.split() for i in email_6p2_df.nostop_stem_doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2771"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['baker',\n",
       "  'swept',\n",
       "  'edward',\n",
       "  'hirsch',\n",
       "  'audio',\n",
       "  'read',\n",
       "  'author',\n",
       "  'alreadi',\n",
       "  'lose',\n",
       "  'eyesight',\n",
       "  'last',\n",
       "  'winter',\n",
       "  'rome',\n",
       "  'paus',\n",
       "  'doorway',\n",
       "  'nine',\n",
       "  'clock',\n",
       "  'saturday',\n",
       "  'morn',\n",
       "  'baker',\n",
       "  'swept',\n",
       "  'shini',\n",
       "  'bicycl',\n",
       "  'wave',\n",
       "  'cap',\n",
       "  'sing',\n",
       "  'breath',\n",
       "  'know',\n",
       "  'baker',\n",
       "  'wore',\n",
       "  'white',\n",
       "  'apron',\n",
       "  'dust',\n",
       "  'flour',\n",
       "  'float',\n",
       "  'around',\n",
       "  'citi',\n",
       "  'like',\n",
       "  'angel',\n",
       "  'freshli',\n",
       "  'bake',\n",
       "  'day',\n",
       "  'sure',\n",
       "  'morn',\n",
       "  'halt',\n",
       "  'street',\n",
       "  'stood',\n",
       "  'doorway',\n",
       "  'baker',\n",
       "  'wing',\n",
       "  'weekend',\n",
       "  'morn',\n",
       "  'new',\n",
       "  'pristin',\n",
       "  'look',\n",
       "  'sky',\n",
       "  'one',\n",
       "  'undiminish',\n",
       "  'instant',\n",
       "  'misplac',\n",
       "  'time',\n",
       "  'saw',\n",
       "  'bright',\n",
       "  'bright',\n",
       "  'everywher',\n",
       "  'shadow',\n",
       "  'cross',\n",
       "  'rooftop',\n",
       "  'blot'],\n",
       " ['get',\n",
       "  'rate',\n",
       "  'rotten',\n",
       "  'tomato',\n",
       "  'ever',\n",
       "  'fact',\n",
       "  'jordan',\n",
       "  'peel',\n",
       "  'get',\n",
       "  'one',\n",
       "  'film',\n",
       "  'thriller',\n",
       "  'sit',\n",
       "  'impress',\n",
       "  'fresh',\n",
       "  'rotten',\n",
       "  'tomato',\n",
       "  'one',\n",
       "  'point',\n",
       "  'film',\n",
       "  'held',\n",
       "  'steadi',\n",
       "  'fresh',\n",
       "  'score',\n",
       "  'came',\n",
       "  'halt',\n",
       "  'one',\n",
       "  'review',\n",
       "  'rip',\n",
       "  'project',\n",
       "  'nation',\n",
       "  'review',\n",
       "  'armond',\n",
       "  'white',\n",
       "  'describ',\n",
       "  'get',\n",
       "  'headlin',\n",
       "  'review',\n",
       "  'return',\n",
       "  'movi',\n",
       "  'get',\n",
       "  'actor',\n",
       "  'lakeith',\n",
       "  'stanfield',\n",
       "  'definit',\n",
       "  'hide',\n",
       "  'thought',\n",
       "  'white',\n",
       "  'review',\n",
       "  'twitter',\n",
       "  'movi',\n",
       "  'still',\n",
       "  'sit',\n",
       "  'fresh',\n",
       "  'rotten',\n",
       "  'tomato',\n",
       "  'even',\n",
       "  'though',\n",
       "  'ton',\n",
       "  'glow',\n",
       "  'review',\n",
       "  'sinc',\n",
       "  'come',\n",
       "  'fresh',\n",
       "  'review',\n",
       "  'one',\n",
       "  'rotten',\n",
       "  'one',\n",
       "  'never',\n",
       "  'get',\n",
       "  'back',\n",
       "  'round',\n",
       "  'nearest',\n",
       "  'whole',\n",
       "  'number',\n",
       "  'two',\n",
       "  'except',\n",
       "  'repres',\n",
       "  'rotten',\n",
       "  'tomato',\n",
       "  'told',\n",
       "  'buzzfe',\n",
       "  'news',\n",
       "  'round',\n",
       "  'round',\n",
       "  'reserv',\n",
       "  'absolut',\n",
       "  'movi',\n",
       "  'everi',\n",
       "  'singl',\n",
       "  'review',\n",
       "  'fresh',\n",
       "  'everi',\n",
       "  'singl',\n",
       "  'review',\n",
       "  'rotten',\n",
       "  'armond',\n",
       "  'white',\n",
       "  'say'],\n",
       " ['know',\n",
       "  'right',\n",
       "  'safeti',\n",
       "  'risk',\n",
       "  'interact',\n",
       "  'polic',\n",
       "  'shock',\n",
       "  'video',\n",
       "  'upload',\n",
       "  'youtub',\n",
       "  'recent',\n",
       "  'show',\n",
       "  'man',\n",
       "  'newington',\n",
       "  'connecticut',\n",
       "  'refus',\n",
       "  'fall',\n",
       "  'polic',\n",
       "  'state',\n",
       "  'tactic',\n",
       "  'intimid',\n",
       "  'polic',\n",
       "  'checkpoint',\n",
       "  'wide',\n",
       "  'known',\n",
       "  'sobrieti',\n",
       "  'dui',\n",
       "  'checkpoint',\n",
       "  'realiti',\n",
       "  'amount',\n",
       "  'excus',\n",
       "  'cop',\n",
       "  'surveil',\n",
       "  'keep',\n",
       "  'tab',\n",
       "  'citizen',\n",
       "  'say',\n",
       "  'cop',\n",
       "  'keep',\n",
       "  'safe',\n",
       "  'realiti',\n",
       "  'absolut',\n",
       "  'differ',\n",
       "  'pig',\n",
       "  'fill',\n",
       "  'prison',\n",
       "  'profit',\n",
       "  'quota',\n",
       "  'arrest',\n",
       "  'quota',\n",
       "  'cking',\n",
       "  'quota',\n",
       "  'rememb',\n",
       "  'polic',\n",
       "  'guarante',\n",
       "  'peac',\n",
       "  'street',\n",
       "  'polic',\n",
       "  'state',\n",
       "  'america',\n",
       "  'moral',\n",
       "  'stori',\n",
       "  'educ',\n",
       "  'stand',\n",
       "  'constitut',\n",
       "  'right',\n",
       "  'take',\n",
       "  'power',\n",
       "  'back',\n",
       "  'public',\n",
       "  'servant',\n",
       "  'powertothepeopl',\n",
       "  'mani',\n",
       "  'togeth',\n",
       "  'stop',\n",
       "  'policeterror']]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_list[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tokenize text with gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = gs.corpora.Dictionary(doc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14938"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dictionary.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [dictionary.doc2bow(text) for text in doc_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2771"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get `bi_weapon_array`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Authority or Expertise/Source Credibility',\n",
       " 'Blame/guilt',\n",
       " 'Commitment',\n",
       " 'Commitment- Call to Action',\n",
       " 'Commitment- Indignation',\n",
       " 'Emphasis',\n",
       " 'Gain framing',\n",
       " 'Liking',\n",
       " 'Loss framing',\n",
       " 'Objectivity',\n",
       " 'Reciprocation',\n",
       " 'Scarcity/Urgency/Opportunity',\n",
       " 'Social Proof',\n",
       " 'Social Proof- Admonition',\n",
       " 'Subjectivity']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(email_6p2_df.columns[-15:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Emphasis',)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Authority or Expertise/Source Credibility',\n",
    "'Commitment',\n",
    "'Commitment- Call to Action',\n",
    "'Subjectivity',\n",
    "'Gain framing',\n",
    "'Blame/guilt',\n",
    "'Emphasis',\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Authority or Expertise/Source Credibility',\n",
       " 'Commitment',\n",
       " 'Liking',\n",
       " 'Social Proof',\n",
       " 'Scarcity/Urgency/Opportunity',\n",
       " 'Gain framing',\n",
       " 'Loss framing')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Authority or Expertise/Source Credibility', 'Commitment', 'Liking', 'Social Proof', 'Scarcity/Urgency/Opportunity', 'Gain framing', 'Loss framing',"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "influence_list = ['authority', 'commitment', 'liking', 'social', 'scarcity', 'reward', 'loss',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Authority or Expertise/Source Credibility',\n",
       " 'Commitment',\n",
       " 'Commitment- Call to Action',\n",
       " 'Subjectivity',\n",
       " 'Gain framing',\n",
       " 'Blame/guilt',\n",
       " 'Emphasis']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2021-06-30\n",
    "influence_list = [\n",
    "    'Authority or Expertise/Source Credibility',\n",
    "    'Commitment',\n",
    "    'Commitment- Call to Action',\n",
    "    'Subjectivity',\n",
    "    'Gain framing',\n",
    "    'Blame/guilt',\n",
    "    'Emphasis',\n",
    "]\n",
    "\n",
    "influence_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_weapon_array = email_6p2_df[influence_list].values.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2771, 7)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 1, 0, ..., 0, 1, 0],\n",
       "       [0, 1, 1, ..., 0, 1, 1],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       [1, 1, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 1]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(bi_weapon_array.shape)\n",
    "bi_weapon_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bi_weapon_array[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cross validation & grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics_list = [10,  50, 100]\n",
    "n_estimators_list = [50, 100, 200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 50\n",
      "len of dictionary.keys:  13352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hanyushi/projects/s02_DeceptiveCues/src/obtainLDA/lda_liwc_sia_learn.py:26: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  doc_array = np.array(doc_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of dictionary.keys:  13305\n",
      "len of dictionary.keys:  13337\n",
      "len of dictionary.keys:  13484\n",
      "len of dictionary.keys:  13418\n",
      "acc_score         0.723153\n",
      "f1_score_macro    0.580004\n",
      "f1_score_micro    0.686855\n",
      "dtype: float64\n",
      "10 100\n",
      "len of dictionary.keys:  13419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hanyushi/projects/s02_DeceptiveCues/src/obtainLDA/lda_liwc_sia_learn.py:26: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  doc_array = np.array(doc_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of dictionary.keys:  13453\n",
      "len of dictionary.keys:  13487\n",
      "len of dictionary.keys:  13199\n",
      "len of dictionary.keys:  13403\n",
      "acc_score         0.720519\n",
      "f1_score_macro    0.578404\n",
      "f1_score_micro    0.686856\n",
      "dtype: float64\n",
      "10 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hanyushi/projects/s02_DeceptiveCues/src/obtainLDA/lda_liwc_sia_learn.py:26: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  doc_array = np.array(doc_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of dictionary.keys:  13394\n",
      "len of dictionary.keys:  13332\n",
      "len of dictionary.keys:  13363\n",
      "len of dictionary.keys:  13408\n",
      "len of dictionary.keys:  13398\n",
      "acc_score         0.722431\n",
      "f1_score_macro    0.583675\n",
      "f1_score_micro    0.690359\n",
      "dtype: float64\n",
      "50 50\n",
      "len of dictionary.keys:  13370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hanyushi/projects/s02_DeceptiveCues/src/obtainLDA/lda_liwc_sia_learn.py:26: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  doc_array = np.array(doc_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of dictionary.keys:  13420\n",
      "len of dictionary.keys:  13445\n",
      "len of dictionary.keys:  13352\n",
      "len of dictionary.keys:  13328\n",
      "acc_score         0.717484\n",
      "f1_score_macro    0.567411\n",
      "f1_score_micro    0.681112\n",
      "dtype: float64\n",
      "50 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hanyushi/projects/s02_DeceptiveCues/src/obtainLDA/lda_liwc_sia_learn.py:26: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  doc_array = np.array(doc_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of dictionary.keys:  13284\n",
      "len of dictionary.keys:  13539\n",
      "len of dictionary.keys:  13284\n",
      "len of dictionary.keys:  13409\n",
      "len of dictionary.keys:  13426\n",
      "acc_score         0.721867\n",
      "f1_score_macro    0.571428\n",
      "f1_score_micro    0.686420\n",
      "dtype: float64\n",
      "50 200\n",
      "len of dictionary.keys:  13313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hanyushi/projects/s02_DeceptiveCues/src/obtainLDA/lda_liwc_sia_learn.py:26: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  doc_array = np.array(doc_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of dictionary.keys:  13456\n",
      "len of dictionary.keys:  13336\n",
      "len of dictionary.keys:  13354\n",
      "len of dictionary.keys:  13465\n",
      "acc_score         0.722067\n",
      "f1_score_macro    0.569449\n",
      "f1_score_micro    0.686604\n",
      "dtype: float64\n",
      "100 50\n",
      "len of dictionary.keys:  13371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hanyushi/projects/s02_DeceptiveCues/src/obtainLDA/lda_liwc_sia_learn.py:26: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  doc_array = np.array(doc_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of dictionary.keys:  13483\n",
      "len of dictionary.keys:  13366\n",
      "len of dictionary.keys:  13286\n",
      "len of dictionary.keys:  13419\n",
      "acc_score         0.715006\n",
      "f1_score_macro    0.561255\n",
      "f1_score_micro    0.675798\n",
      "dtype: float64\n",
      "100 100\n",
      "len of dictionary.keys:  13435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hanyushi/projects/s02_DeceptiveCues/src/obtainLDA/lda_liwc_sia_learn.py:26: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  doc_array = np.array(doc_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of dictionary.keys:  13269\n",
      "len of dictionary.keys:  13472\n",
      "len of dictionary.keys:  13336\n",
      "len of dictionary.keys:  13388\n",
      "acc_score         0.719286\n",
      "f1_score_macro    0.565551\n",
      "f1_score_micro    0.681581\n",
      "dtype: float64\n",
      "100 200\n",
      "len of dictionary.keys:  13330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hanyushi/projects/s02_DeceptiveCues/src/obtainLDA/lda_liwc_sia_learn.py:26: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  doc_array = np.array(doc_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of dictionary.keys:  13532\n",
      "len of dictionary.keys:  13258\n",
      "len of dictionary.keys:  13376\n",
      "len of dictionary.keys:  13445\n",
      "acc_score         0.716914\n",
      "f1_score_macro    0.561294\n",
      "f1_score_micro    0.680062\n",
      "dtype: float64\n",
      "CPU times: user 8min 7s, sys: 41.3 s, total: 8min 49s\n",
      "Wall time: 6min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "max_f1_score_micro = 0\n",
    "optimal_parameter_dic = {}\n",
    "\n",
    "for num_topics, n_estimators in itertools.product(num_topics_list, n_estimators_list):\n",
    "    print(num_topics, n_estimators)\n",
    "    \n",
    "    df_result_f1_score_save = run_lda_liwc_sia_rf(doc_list, liwc_sia_array, bi_weapon_array, num_topics=num_topics, n_estimators=n_estimators)\n",
    "    \n",
    "    print(df_result_f1_score_save.mean())\n",
    "    \n",
    "    tmp_f1_score_micro = df_result_f1_score_save.mean().f1_score_micro\n",
    "    \n",
    "    if tmp_f1_score_micro > max_f1_score_micro * 1.001:\n",
    "        max_f1_score_micro = tmp_f1_score_micro\n",
    "        optimal_parameter_dic['num_topics'] = num_topics\n",
    "        optimal_parameter_dic['n_estimators'] = n_estimators\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### optimal run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6903589752973892"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_f1_score_micro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_topics': 10, 'n_estimators': 200}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_parameter_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics = optimal_parameter_dic['num_topics']\n",
    "n_estimators = optimal_parameter_dic['n_estimators']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hanyushi/projects/s02_DeceptiveCues/src/obtainLDA/lda_liwc_sia_learn.py:26: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  doc_array = np.array(doc_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of dictionary.keys:  13347\n",
      "len of dictionary.keys:  13323\n",
      "len of dictionary.keys:  13358\n",
      "len of dictionary.keys:  13447\n",
      "len of dictionary.keys:  13453\n"
     ]
    }
   ],
   "source": [
    "df_result_f1_score_save = run_lda_liwc_sia_rf(doc_list, liwc_sia_array, bi_weapon_array, num_topics=num_topics, n_estimators=n_estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_score</th>\n",
       "      <th>f1_score_macro</th>\n",
       "      <th>f1_score_micro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.727156</td>\n",
       "      <td>0.595442</td>\n",
       "      <td>0.697143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.723053</td>\n",
       "      <td>0.581800</td>\n",
       "      <td>0.692440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.723053</td>\n",
       "      <td>0.586928</td>\n",
       "      <td>0.695751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.722280</td>\n",
       "      <td>0.570969</td>\n",
       "      <td>0.686828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.726147</td>\n",
       "      <td>0.580104</td>\n",
       "      <td>0.689836</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   acc_score  f1_score_macro  f1_score_micro\n",
       "0   0.727156        0.595442        0.697143\n",
       "1   0.723053        0.581800        0.692440\n",
       "2   0.723053        0.586928        0.695751\n",
       "3   0.722280        0.570969        0.686828\n",
       "4   0.726147        0.580104        0.689836"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result_f1_score_save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "acc_score         0.724338\n",
       "f1_score_macro    0.583049\n",
       "f1_score_micro    0.692399\n",
       "dtype: float64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result_f1_score_save.mean()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "acc_score         0.725987\n",
    "f1_score_macro    0.583181\n",
    "f1_score_micro    0.692538\n",
    "dtype: float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 27.8 ms, sys: 20.6 ms, total: 48.4 ms\n",
      "Wall time: 718 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import beepy\n",
    "beepy.beep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "193.875px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
